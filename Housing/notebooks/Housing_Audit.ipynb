{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "#we need to tell polars to treat 'NA' as 'Null' so it doesn't get confused between text and numbers\n",
    "df = pl.read_csv('../Data/train.csv',\n",
    "                 null_values='NA',\n",
    "                infer_schema_length=1000 \n",
    ")\n",
    "\n",
    "#check the size of our data\n",
    "print(f'The dataset contains {df.height} rows and {df.width} columns.')\n",
    "\n",
    "#identify the columns with missing values\n",
    "#create a list of columns and their missing value counts\n",
    "null_summary = df.null_count().melt().filter(pl.col('value') > 0).sort('value', descending=True)\n",
    "\n",
    "#view the list without truncation\n",
    "with pl.Config(tbl_rows=100):\n",
    "    print(null_summary)\n",
    "\n",
    "#create a list of the 'Ghost' columns we want to drop, then drop them.\n",
    "ghost_columns = ['PoolQC', 'MiscFeature', 'Alley', 'Fence']\n",
    "\n",
    "df_reduced = df.drop(ghost_columns)\n",
    "print(f'New column count: {df_reduced.width}')\n",
    "\n",
    "#Columns where Null means Feature not present\n",
    "structural_cols = [\n",
    "    'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "    'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'\n",
    "]\n",
    "\n",
    "#Fill Nulls with None\n",
    "df_structural = df_reduced.with_columns([\n",
    "    pl.col(col).fill_null('None') for col in structural_cols\n",
    "])\n",
    "\n",
    "#Verify no Nulls remain in these columns\n",
    "print(f'Nulls in FireplaceQu after fix: {df_structural[\"FireplaceQu\"].null_count()}')\n",
    "\n",
    "# Calculate the median of the street frontage\n",
    "median_value = df_structural[\"LotFrontage\"].median()\n",
    "\n",
    "# Fill the holes with that median\n",
    "df_final_audit = df_structural.with_columns(\n",
    "    pl.col(\"LotFrontage\").fill_null(median_value)\n",
    ")\n",
    "\n",
    "print(f\"LotFrontage median used: {median_value}\")\n",
    "print(f\"Total remaining nulls in dataset: {df_final_audit.null_count().sum().sum()}\")\n",
    "\n",
    "\n",
    "#we now have a fairly solid dataset to work with.\n",
    "#which columns dictate the price?\n",
    "numeric_df = df_final_audit.select(pl.col(pl.Int64, pl.Float64)) #select numeric columns for correlation analysis\n",
    "\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "price_correlations = (\n",
    "    corr_matrix.with_columns(\n",
    "        pl.Series(\"Feature\", numeric_df.columns)\n",
    "    )\n",
    "    .select([\n",
    "        pl.col(\"Feature\"),\n",
    "        pl.col(\"SalePrice\")\n",
    "    ])\n",
    "    .sort(\"SalePrice\", descending=True)\n",
    ")\n",
    "\n",
    "with pl.Config(tbl_rows=150):\n",
    "    print(price_correlations)\n",
    "\n",
    "#checking for independance\n",
    "garage_overlap = numeric_df.select(pl.corr(\"GarageArea\", \"GarageCars\"))\n",
    "size_overlap = numeric_df.select(pl.corr('GrLivArea', 'TotalBsmtSF'))\n",
    "\n",
    "print(f'Garage overlap: {garage_overlap[0,0]:.4f}')\n",
    "print(f'Size overlap: {size_overlap[0,0]:.4f}')\n",
    "\n",
    "#drop GarageArea since it overlaps heavily with GarageCars.\n",
    "df_final_audit = df_final_audit.drop('GarageArea')\n",
    "\n",
    "#Search for outliers.\n",
    "# Filter for houses that are huge (GrLivArea > 4000)\n",
    "outliers = df_final_audit.filter(pl.col(\"GrLivArea\") > 4000)\n",
    "\n",
    "# Let's see their Price vs their Size\n",
    "print(\"Potential Outliers (Huge Houses):\")\n",
    "print(outliers.select([\"Id\", \"GrLivArea\", \"SalePrice\", \"OverallQual\"]))\n",
    "\n",
    "# Remove the outliers by keeping only houses under 4000 sq ft\n",
    "df_final_audit = df_final_audit.filter(pl.col(\"GrLivArea\") < 4000)\n",
    "\n",
    "print(f\"Outliers removed. Final row count: {df_final_audit.height}\")\n",
    "\n",
    "# Save to the data folder so we can find it easily tomorrow\n",
    "df_final_audit.write_csv(\"../Data/train_cleaned.csv\")\n",
    "\n",
    "print(\"File saved successfully as 'train_cleaned.csv' in your data folder!\")\n",
    "\n",
    "#EDA.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#1. Is the SalePrice Noramally Distributed?\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df_final_audit['SalePrice'], kde=True, color='blue')\n",
    "plt.title('Distribution of SalePrice')\n",
    "plt.show()\n",
    "\n",
    "#2. We know price increases with overall quality, but how is the relationship between the two?\n",
    "import pandas as pd\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='OverallQual', y='SalePrice', data=df_final_audit.to_pandas())\n",
    "plt.title('Sales Price as Quality increases')\n",
    "plt.show()\n",
    "\n",
    "#3. Checking for any clustering in our data, to add on to correlations\n",
    "plt.figure(figsize=(14, 10))\n",
    "top_features = price_correlations['Feature'].head(15).to_list() #correlate only the top 15 features to keep it readable\n",
    "sns.heatmap(numeric_df.select(top_features).corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of top 15 Features')\n",
    "plt.show()\n",
    "\n",
    "# Print the top 15 features and their correlation with SalePrice\n",
    "with pl.Config(tbl_rows=15):\n",
    "    print(price_correlations.head(15))\n",
    "\n",
    "import numpy as np\n",
    "#the cleaning continues...\n",
    "#1. Drop redundant columns\n",
    "df_final_audit = df_final_audit.drop(['1stFlrSF'])\n",
    "\n",
    "#2. Engineer the Spaciousness feature\n",
    "df_final_audit = df_final_audit.with_columns(\n",
    "    (pl.col('GrLivArea')/pl.col('TotRmsAbvGrd')).alias('SqFtPerRoom')\n",
    ")\n",
    "\n",
    "#3. Apply log transformation to SalePrice to reduce skewness\n",
    "df_final_audit = df_final_audit.with_columns(\n",
    "    pl.col('SalePrice').log().alias('LogSalePrice')\n",
    ")\n",
    "\n",
    "print('Audit and EDA complete')\n",
    "print(f'Columns remaining: {df_final_audit.width}')\n",
    "print(f'New Feature, \"SqFtPerRoom\", added.')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plotting area\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. The Raw Data (The 'Slide')\n",
    "sns.histplot(df_final_audit['SalePrice'], kde=True, color='#FF5733', ax=ax1)\n",
    "ax1.set_title('Original SalePrice (Right-Skewed)')\n",
    "ax1.set_xlabel('Price in Dollars')\n",
    "\n",
    "# 2. The Log-Transformed Data (The 'Bell')\n",
    "sns.histplot(df_final_audit['LogSalePrice'], kde=True, color='#2ECC71', ax=ax2)\n",
    "ax2.set_title('Log-Transformed SalePrice (Normal Distribution)')\n",
    "ax2.set_xlabel('Log of Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f'Log transformation applied to SalePrice, new column \"LogSalePrice\" created.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_mastery (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
